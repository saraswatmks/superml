<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Extreme Gradient Boosting Trainer — XGBTrainer • SuperML</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Extreme Gradient Boosting Trainer — XGBTrainer"><meta property="og:description" content="Trains a XGBoost model in R"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SuperML</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.5.6</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/superml_tutorial.html">Introduction to superml</a>
    </li>
    <li>
      <a href="../articles/Guide-to-CountVectorizer.html">Guide to CountVectorizer</a>
    </li>
    <li>
      <a href="../articles/Guide-to-TfidfVectorizer.html">Guide to TfIdfVectorizer</a>
    </li>
  </ul></li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/saraswatmks/superml" class="external-link">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/saraswatmanish/" class="external-link">
    <span class="fa fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Extreme Gradient Boosting Trainer</h1>
    <small class="dont-index">Source: <a href="https://github.com/saraswatmks/superml/blob/HEAD/R/XGBoost.R" class="external-link"><code>R/XGBoost.R</code></a></small>
    <div class="hidden name"><code>XGBTrainer.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Trains a XGBoost model in R</p>
    </div>


    <div id="details">
    <h2>Details</h2>
    <p>Trains a Extreme Gradient Boosting Model. XGBoost belongs to a family of boosting algorithms
that creates an ensemble of weak learner to learn about data. It is a wrapper for original xgboost
R package, you can find the documentation here: <a href="http://xgboost.readthedocs.io/en/latest/parameter.html" class="external-link">http://xgboost.readthedocs.io/en/latest/parameter.html</a></p>
    </div>
    <div id="public-fields">
    <h2>Public fields</h2>
    <p></p><div class="r6-fields"><dl><dt><code>booster</code></dt>
<dd><p>the trainer type, the values are <code>gbtree(default)</code>, <code>gblinear</code>, <code>dart:gbtree</code></p></dd>


<dt><code>objective</code></dt>
<dd><p>specify the learning task. Check the link above for all possible values.</p></dd>


<dt><code>nthread</code></dt>
<dd><p>number of parallel threads used to run, default is to run using all threads available</p></dd>


<dt><code>silent</code></dt>
<dd><p>0 means printing running messages, 1 means silent mode</p></dd>


<dt><code>n_estimators</code></dt>
<dd><p>number of trees to grow, default = 100</p></dd>


<dt><code>learning_rate</code></dt>
<dd><p>Step size shrinkage used in update to prevents overfitting. Lower the learning rate, more time it takes in training, value lies between between 0 and 1. Default = 0.3</p></dd>


<dt><code>gamma</code></dt>
<dd><p>Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be. Value lies between 0 and infinity, Default = 0</p></dd>


<dt><code>max_depth</code></dt>
<dd><p>the maximum depth of each tree, default = 6</p></dd>


<dt><code>min_child_weight</code></dt>
<dd><p>Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. The larger min_child_weight is, the more conservative the algorithm will be. Value lies between 0 and infinity. Default = 1</p></dd>


<dt><code>subsample</code></dt>
<dd><p>Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. Subsampling will occur once in every boosting iteration. Value lies between 0 and 1. Default = 1</p></dd>


<dt><code>colsample_bytree</code></dt>
<dd><p>Subsample ratio of columns when constructing each tree. Subsampling will occur once in every boosting iteration. Value lies between 0 and 1. Default = 1</p></dd>


<dt><code>lambda</code></dt>
<dd><p>L2 regularization term on weights. Increasing this value will make model more conservative. Default = 1</p></dd>


<dt><code>alpha</code></dt>
<dd><p>L1 regularization term on weights. Increasing this value will make model more conservative. Default = 0</p></dd>


<dt><code>eval_metric</code></dt>
<dd><p>Evaluation metrics for validation data, a default metric will be assigned according to objective</p></dd>


<dt><code>print_every</code></dt>
<dd><p>print training log after n iterations. Default = 50</p></dd>


<dt><code>feval</code></dt>
<dd><p>custom evaluation function</p></dd>


<dt><code>early_stopping</code></dt>
<dd><p>Used to prevent overfitting, stops model training after this number of iterations if there is no improvement seen</p></dd>


<dt><code>maximize</code></dt>
<dd><p>If feval and early_stopping_rounds are set, then this parameter must be set as well. When it is TRUE, it means the larger the evaluation score the better.</p></dd>


<dt><code>custom_objective</code></dt>
<dd><p>custom objective function</p></dd>


<dt><code>save_period</code></dt>
<dd><p>when it is non-NULL, model is saved to disk after every save_period rounds, 0 means save at the end.</p></dd>


<dt><code>save_name</code></dt>
<dd><p>the name or path for periodically saved model file.</p></dd>


<dt><code>xgb_model</code></dt>
<dd><p>a previously built model to continue the training from. Could be either an object of class xgb.Booster, or its raw data, or the name of a file with a previously saved model.</p></dd>


<dt><code>callbacks</code></dt>
<dd><p>a list of callback functions to perform various task during boosting. See callbacks. Some of the callbacks are automatically created depending on the parameters' values. User can provide either existing or their own callback methods in order to customize the training process.</p></dd>


<dt><code>verbose</code></dt>
<dd><p>If 0, xgboost will stay silent. If 1, xgboost will print information of performance. If 2, xgboost will print some additional information. Setting verbose &gt; 0 automatically engages the cb.evaluation.log and cb.print.evaluation callback functions.</p></dd>


<dt><code>watchlist</code></dt>
<dd><p>what information should be printed when verbose=1 or verbose=2. Watchlist is used to specify validation set monitoring during training. For example user can specify watchlist=list(validation1=mat1, validation2=mat2) to watch the performance of each round's model on mat1 and mat2</p></dd>


<dt><code>num_class</code></dt>
<dd><p>set number of classes in case of multiclassification problem</p></dd>


<dt><code>weight</code></dt>
<dd><p>a vector indicating the weight for each row of the input.</p></dd>


<dt><code>na_missing</code></dt>
<dd><p>by default is set to NA, which means that NA values should be considered as 'missing' by the algorithm. Sometimes, 0 or other extreme value might be used to represent missing values. This parameter is only used when input is a dense matrix.</p></dd>


<dt><code>feature_names</code></dt>
<dd><p>internal use, stores the feature names for model importance</p></dd>


<dt><code>cv_model</code></dt>
<dd><p>internal use</p></dd>


</dl><p></p></div>
    </div>
    <div id="methods">
    <h2>Methods</h2>
    
<div class="section">
<h3 id="public-methods">Public methods<a class="anchor" aria-label="anchor" href="#public-methods"></a></h3>

<ul><li><p><a href="#method-XGBTrainer-new"><code>XGBTrainer$new()</code></a></p></li>
<li><p><a href="#method-XGBTrainer-cross_val"><code>XGBTrainer$cross_val()</code></a></p></li>
<li><p><a href="#method-XGBTrainer-fit"><code>XGBTrainer$fit()</code></a></p></li>
<li><p><a href="#method-XGBTrainer-predict"><code>XGBTrainer$predict()</code></a></p></li>
<li><p><a href="#method-XGBTrainer-show_importance"><code>XGBTrainer$show_importance()</code></a></p></li>
<li><p><a href="#method-XGBTrainer-clone"><code>XGBTrainer$clone()</code></a></p></li>
</ul></div><p></p><hr><a id="method-XGBTrainer-new"></a><div class="section">
<h3 id="method-new-">Method <code>new()</code><a class="anchor" aria-label="anchor" href="#method-new-"></a></h3>

<div class="section">
<h4 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va"><a href="../reference/XGBTrainer.html">XGBTrainer</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span></span>
<span>  <span class="va">booster</span>,</span>
<span>  <span class="va">objective</span>,</span>
<span>  <span class="va">nthread</span>,</span>
<span>  <span class="va">silent</span>,</span>
<span>  <span class="va">n_estimators</span>,</span>
<span>  <span class="va">learning_rate</span>,</span>
<span>  <span class="va">gamma</span>,</span>
<span>  <span class="va">max_depth</span>,</span>
<span>  <span class="va">min_child_weight</span>,</span>
<span>  <span class="va">subsample</span>,</span>
<span>  <span class="va">colsample_bytree</span>,</span>
<span>  <span class="va">lambda</span>,</span>
<span>  <span class="va">alpha</span>,</span>
<span>  <span class="va">eval_metric</span>,</span>
<span>  <span class="va">print_every</span>,</span>
<span>  <span class="va">feval</span>,</span>
<span>  <span class="va">early_stopping</span>,</span>
<span>  <span class="va">maximize</span>,</span>
<span>  <span class="va">custom_objective</span>,</span>
<span>  <span class="va">save_period</span>,</span>
<span>  <span class="va">save_name</span>,</span>
<span>  <span class="va">xgb_model</span>,</span>
<span>  <span class="va">callbacks</span>,</span>
<span>  <span class="va">verbose</span>,</span>
<span>  <span class="va">num_class</span>,</span>
<span>  <span class="va">weight</span>,</span>
<span>  <span class="va">na_missing</span></span>
<span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h4>
<p></p><div class="arguments"><dl><dt><code>booster</code></dt>
<dd><p>the trainer type, the values are <code>gbtree(default)</code>, <code>gblinear</code>, <code>dart:gbtree</code></p></dd>


<dt><code>objective</code></dt>
<dd><p>specify the learning task. Check the link above for all possible values.</p></dd>


<dt><code>nthread</code></dt>
<dd><p>number of parallel threads used to run, default is to run using all threads available</p></dd>


<dt><code>silent</code></dt>
<dd><p>0 means printing running messages, 1 means silent mode</p></dd>


<dt><code>n_estimators</code></dt>
<dd><p>number of trees to grow, default = 100</p></dd>


<dt><code>learning_rate</code></dt>
<dd><p>Step size shrinkage used in update to prevents overfitting. Lower the learning rate, more time it takes in training, value lies between between 0 and 1. Default = 0.3</p></dd>


<dt><code>gamma</code></dt>
<dd><p>Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be. Value lies between 0 and infinity, Default = 0</p></dd>


<dt><code>max_depth</code></dt>
<dd><p>the maximum depth of each tree, default = 6</p></dd>


<dt><code>min_child_weight</code></dt>
<dd><p>Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. The larger min_child_weight is, the more conservative the algorithm will be. Value lies between 0 and infinity. Default = 1</p></dd>


<dt><code>subsample</code></dt>
<dd><p>Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. Subsampling will occur once in every boosting iteration. Value lies between 0 and 1. Default = 1</p></dd>


<dt><code>colsample_bytree</code></dt>
<dd><p>Subsample ratio of columns when constructing each tree. Subsampling will occur once in every boosting iteration. Value lies between 0 and 1. Default = 1</p></dd>


<dt><code>lambda</code></dt>
<dd><p>L2 regularization term on weights. Increasing this value will make model more conservative. Default = 1</p></dd>


<dt><code>alpha</code></dt>
<dd><p>L1 regularization term on weights. Increasing this value will make model more conservative. Default = 0</p></dd>


<dt><code>eval_metric</code></dt>
<dd><p>Evaluation metrics for validation data, a default metric will be assigned according to objective</p></dd>


<dt><code>print_every</code></dt>
<dd><p>print training log after n iterations. Default = 50</p></dd>


<dt><code>feval</code></dt>
<dd><p>custom evaluation function</p></dd>


<dt><code>early_stopping</code></dt>
<dd><p>Used to prevent overfitting, stops model training after this number of iterations if there is no improvement seen</p></dd>


<dt><code>maximize</code></dt>
<dd><p>If feval and early_stopping_rounds are set, then this parameter must be set as well. When it is TRUE, it means the larger the evaluation score the better.</p></dd>


<dt><code>custom_objective</code></dt>
<dd><p>custom objective function</p></dd>


<dt><code>save_period</code></dt>
<dd><p>when it is non-NULL, model is saved to disk after every save_period rounds, 0 means save at the end.</p></dd>


<dt><code>save_name</code></dt>
<dd><p>the name or path for periodically saved model file.</p></dd>


<dt><code>xgb_model</code></dt>
<dd><p>a previously built model to continue the training from. Could be either an object of class xgb.Booster, or its raw data, or the name of a file with a previously saved model.</p></dd>


<dt><code>callbacks</code></dt>
<dd><p>a list of callback functions to perform various task during boosting. See callbacks. Some of the callbacks are automatically created depending on the parameters' values. User can provide either existing or their own callback methods in order to customize the training process.</p></dd>


<dt><code>verbose</code></dt>
<dd><p>If 0, xgboost will stay silent. If 1, xgboost will print information of performance. If 2, xgboost will print some additional information. Setting verbose &gt; 0 automatically engages the cb.evaluation.log and cb.print.evaluation callback functions.</p></dd>


<dt><code>num_class</code></dt>
<dd><p>set number of classes in case of multiclassification problem</p></dd>


<dt><code>weight</code></dt>
<dd><p>a vector indicating the weight for each row of the input.</p></dd>


<dt><code>na_missing</code></dt>
<dd><p>by default is set to NA, which means that NA values should be considered as 'missing' by the algorithm. Sometimes, 0 or other extreme value might be used to represent missing values. This parameter is only used when input is a dense matrix.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h4>
<p>Create a new `XGBTrainer` object.</p>
</div>

<div class="section">
<h4 id="returns">Returns<a class="anchor" aria-label="anchor" href="#returns"></a></h4>
<p>A `XGBTrainer` object.</p>
</div>
<div class="section">
<h4 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a></h4>
<p></p><div class="r example copy"><div class="sourceCode"><pre><code><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># convert characters/factors to numeric</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span>
<span></span>
<span><span class="co"># initialise model</span></span>
<span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/XGBTrainer.html">XGBTrainer</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span>
<span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span>
<span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span>
<span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-XGBTrainer-cross_val"></a><div class="section">
<h3 id="method-cross-val-">Method <code>cross_val()</code><a class="anchor" aria-label="anchor" href="#method-cross-val-"></a></h3>

<div class="section">
<h4 id="usage-1">Usage<a class="anchor" aria-label="anchor" href="#usage-1"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">cross_val</span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, stratified <span class="op">=</span> <span class="cn">TRUE</span>, folds <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-1">Arguments<a class="anchor" aria-label="anchor" href="#arguments-1"></a></h4>
<p></p><div class="arguments"><dl><dt><code>X</code></dt>
<dd><p>data.frame</p></dd>


<dt><code>y</code></dt>
<dd><p>character, name of target variable</p></dd>


<dt><code>nfolds</code></dt>
<dd><p>integer, number of folds</p></dd>


<dt><code>stratified</code></dt>
<dd><p>logical, whether to use stratified sampling</p></dd>


<dt><code>folds</code></dt>
<dd><p>the list of CV folds' indices - either those passed through the folds parameter or randomly generated.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="details-1">Details<a class="anchor" aria-label="anchor" href="#details-1"></a></h4>
<p>Trains the xgboost model using cross validation scheme</p>
</div>

<div class="section">
<h4 id="returns-1">Returns<a class="anchor" aria-label="anchor" href="#returns-1"></a></h4>
<p>NULL, trains a model and saves it in memory</p>
</div>
<div class="section">
<h4 id="examples-1">Examples<a class="anchor" aria-label="anchor" href="#examples-1"></a></h4>
<p></p><div class="r example copy"><div class="sourceCode"><pre><code>\dontrun{
library(data.table)
df &lt;- copy(iris)

# convert characters/factors to numeric
df$Species &lt;- as.numeric(as.factor(df$Species))-1

# initialise model
xgb &lt;- XGBTrainer$new(objective = 'multi:softmax',
                      maximize = FALSE,
                      eval_metric = 'merror',
                      num_class=3,
                      n_estimators = 2)

# do cross validation to find optimal value for n_estimators
xgb$cross_val(X = df, y = 'Species',nfolds = 3, stratified = TRUE)
}
</code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-XGBTrainer-fit"></a><div class="section">
<h3 id="method-fit-">Method <code>fit()</code><a class="anchor" aria-label="anchor" href="#method-fit-"></a></h3>

<div class="section">
<h4 id="usage-2">Usage<a class="anchor" aria-label="anchor" href="#usage-2"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">fit</span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, valid <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-2">Arguments<a class="anchor" aria-label="anchor" href="#arguments-2"></a></h4>
<p></p><div class="arguments"><dl><dt><code>X</code></dt>
<dd><p>data.frame, training data</p></dd>


<dt><code>y</code></dt>
<dd><p>character, name of target variable</p></dd>


<dt><code>valid</code></dt>
<dd><p>data.frame, validation data</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="details-2">Details<a class="anchor" aria-label="anchor" href="#details-2"></a></h4>
<p>Fits the xgboost model on given data</p>
</div>

<div class="section">
<h4 id="returns-2">Returns<a class="anchor" aria-label="anchor" href="#returns-2"></a></h4>
<p>NULL, trains a model and keeps it in memory</p>
</div>
<div class="section">
<h4 id="examples-2">Examples<a class="anchor" aria-label="anchor" href="#examples-2"></a></h4>
<p></p><div class="r example copy"><div class="sourceCode"><pre><code><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># convert characters/factors to numeric</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span>
<span></span>
<span><span class="co"># initialise model</span></span>
<span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/XGBTrainer.html">XGBTrainer</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span>
<span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span>
<span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span>
<span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">xgb</span><span class="op">$</span><span class="fu">fit</span><span class="op">(</span><span class="va">df</span>, <span class="st">'Species'</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-XGBTrainer-predict"></a><div class="section">
<h3 id="method-predict-">Method <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code><a class="anchor" aria-label="anchor" href="#method-predict-"></a></h3>

<div class="section">
<h4 id="usage-3">Usage<a class="anchor" aria-label="anchor" href="#usage-3"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-3">Arguments<a class="anchor" aria-label="anchor" href="#arguments-3"></a></h4>
<p></p><div class="arguments"><dl><dt><code>df</code></dt>
<dd><p>data.frame, test data set</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="details-3">Details<a class="anchor" aria-label="anchor" href="#details-3"></a></h4>
<p>Returns predicted values for a given test data</p>
</div>

<div class="section">
<h4 id="returns-3">Returns<a class="anchor" aria-label="anchor" href="#returns-3"></a></h4>
<p>xgboost predictions</p>
</div>
<div class="section">
<h4 id="examples-3">Examples<a class="anchor" aria-label="anchor" href="#examples-3"></a></h4>
<p></p><div class="r example copy"><div class="sourceCode"><pre><code><span><span class="co">#' library(data.table)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># convert characters/factors to numeric</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span>
<span></span>
<span><span class="co"># initialise model</span></span>
<span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/XGBTrainer.html">XGBTrainer</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span>
<span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span>
<span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span>
<span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">xgb</span><span class="op">$</span><span class="fu">fit</span><span class="op">(</span><span class="va">df</span>, <span class="st">'Species'</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># make predictions</span></span>
<span><span class="va">preds</span> <span class="op">&lt;-</span> <span class="va">xgb</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-XGBTrainer-show_importance"></a><div class="section">
<h3 id="method-show-importance-">Method <code>show_importance()</code><a class="anchor" aria-label="anchor" href="#method-show-importance-"></a></h3>

<div class="section">
<h4 id="usage-4">Usage<a class="anchor" aria-label="anchor" href="#usage-4"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">show_importance</span><span class="op">(</span>type <span class="op">=</span> <span class="st">"plot"</span>, topn <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-4">Arguments<a class="anchor" aria-label="anchor" href="#arguments-4"></a></h4>
<p></p><div class="arguments"><dl><dt><code>type</code></dt>
<dd><p>character, could be 'plot' or 'table'</p></dd>


<dt><code>topn</code></dt>
<dd><p>integer, top n features to display</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="details-4">Details<a class="anchor" aria-label="anchor" href="#details-4"></a></h4>
<p>Shows feature importance plot</p>
</div>

<div class="section">
<h4 id="returns-4">Returns<a class="anchor" aria-label="anchor" href="#returns-4"></a></h4>
<p>a table or a plot of feature importance</p>
</div>
<div class="section">
<h4 id="examples-4">Examples<a class="anchor" aria-label="anchor" href="#examples-4"></a></h4>
<p></p><div class="r example copy"><div class="sourceCode"><pre><code>\dontrun{
library(data.table)
df &lt;- copy(iris)

# convert characters/factors to numeric
df$Species &lt;- as.numeric(as.factor(df$Species))-1

# initialise model
xgb &lt;- XGBTrainer$new(objective = 'multi:softmax',
                      maximize = FALSE,
                      eval_metric = 'merror',
                      num_class=3,
                      n_estimators = 2)
xgb$fit(df, 'Species')
xgb$show_importance()
}
</code></pre></div><p></p></div>
</div>


</div><p></p><hr><a id="method-XGBTrainer-clone"></a><div class="section">
<h3 id="method-clone-">Method <code>clone()</code><a class="anchor" aria-label="anchor" href="#method-clone-"></a></h3>
<p>The objects of this class are cloneable with this method.</p><div class="section">
<h4 id="usage-5">Usage<a class="anchor" aria-label="anchor" href="#usage-5"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span>deep <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-5">Arguments<a class="anchor" aria-label="anchor" href="#arguments-5"></a></h4>
<p></p><div class="arguments"><dl><dt><code>deep</code></dt>
<dd><p>Whether to make a deep clone.</p></dd>


</dl><p></p></div>
</div>

</div>

    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span><span class="co">## Method `XGBTrainer$new`</span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># convert characters/factors to numeric</span></span></span>
<span class="r-in"><span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># initialise model</span></span></span>
<span class="r-in"><span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span></span>
<span class="r-in"><span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span></span>
<span class="r-in"><span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span></span>
<span class="r-in"><span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span></span>
<span class="r-in"><span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span><span class="co">## Method `XGBTrainer$cross_val`</span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># convert characters/factors to numeric</span></span></span>
<span class="r-in"><span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># initialise model</span></span></span>
<span class="r-in"><span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span></span>
<span class="r-in"><span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span></span>
<span class="r-in"><span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span></span>
<span class="r-in"><span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span></span>
<span class="r-in"><span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># do cross validation to find optimal value for n_estimators</span></span></span>
<span class="r-in"><span><span class="va">xgb</span><span class="op">$</span><span class="fu">cross_val</span><span class="op">(</span>X <span class="op">=</span> <span class="va">df</span>, y <span class="op">=</span> <span class="st">'Species'</span>,nfolds <span class="op">=</span> <span class="fl">3</span>, stratified <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span><span class="co">## Method `XGBTrainer$fit`</span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># convert characters/factors to numeric</span></span></span>
<span class="r-in"><span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># initialise model</span></span></span>
<span class="r-in"><span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span></span>
<span class="r-in"><span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span></span>
<span class="r-in"><span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span></span>
<span class="r-in"><span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span></span>
<span class="r-in"><span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">xgb</span><span class="op">$</span><span class="fu">fit</span><span class="op">(</span><span class="va">df</span>, <span class="st">'Species'</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> converting the data into xgboost format..</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> starting with training...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [10:51:03] WARNING: amalgamation/../src/learner.cc:627: </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameters: { "nrounds" } might not be used.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   This could be a false alarm, with some parameters getting used by language bindings but</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   then being mistakenly passed down to XGBoost core, or some parameter actually being used</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   but getting flagged wrongly here. Please open an issue if you find any such cases.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1]	train-merror:0.020000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Will train until train_merror hasn't improved in 50 rounds.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2]	train-merror:0.026667 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span><span class="co">## Method `XGBTrainer$predict`</span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">#' library(data.table)</span></span></span>
<span class="r-in"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># convert characters/factors to numeric</span></span></span>
<span class="r-in"><span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># initialise model</span></span></span>
<span class="r-in"><span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span></span>
<span class="r-in"><span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span></span>
<span class="r-in"><span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span></span>
<span class="r-in"><span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span></span>
<span class="r-in"><span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">xgb</span><span class="op">$</span><span class="fu">fit</span><span class="op">(</span><span class="va">df</span>, <span class="st">'Species'</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> converting the data into xgboost format..</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> starting with training...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [10:51:03] WARNING: amalgamation/../src/learner.cc:627: </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Parameters: { "nrounds" } might not be used.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   This could be a false alarm, with some parameters getting used by language bindings but</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   then being mistakenly passed down to XGBoost core, or some parameter actually being used</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   but getting flagged wrongly here. Please open an issue if you find any such cases.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1]	train-merror:0.020000 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Will train until train_merror hasn't improved in 50 rounds.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [2]	train-merror:0.026667 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># make predictions</span></span></span>
<span class="r-in"><span><span class="va">preds</span> <span class="op">&lt;-</span> <span class="va">xgb</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span><span class="co">## Method `XGBTrainer$show_importance`</span></span></span>
<span class="r-in"><span><span class="co">## ------------------------------------------------</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># convert characters/factors to numeric</span></span></span>
<span class="r-in"><span><span class="va">df</span><span class="op">$</span><span class="va">Species</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># initialise model</span></span></span>
<span class="r-in"><span><span class="va">xgb</span> <span class="op">&lt;-</span> <span class="va">XGBTrainer</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>objective <span class="op">=</span> <span class="st">'multi:softmax'</span>,</span></span>
<span class="r-in"><span>                      maximize <span class="op">=</span> <span class="cn">FALSE</span>,</span></span>
<span class="r-in"><span>                      eval_metric <span class="op">=</span> <span class="st">'merror'</span>,</span></span>
<span class="r-in"><span>                      num_class<span class="op">=</span><span class="fl">3</span>,</span></span>
<span class="r-in"><span>                      n_estimators <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">xgb</span><span class="op">$</span><span class="fu">fit</span><span class="op">(</span><span class="va">df</span>, <span class="st">'Species'</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">xgb</span><span class="op">$</span><span class="fu">show_importance</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Manish Saraswat.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

      </footer></div>

  


  

  </body></html>

